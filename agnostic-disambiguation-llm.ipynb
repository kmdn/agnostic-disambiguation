{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers\n",
    "#!pip install jinja2 --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from huggingface_hub import notebook_login\n",
    "#notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mention data\n",
    "from pynif import NIFCollection\n",
    "\n",
    "nif_data_path = \"C:\\\\Users\\\\wf7467\\\\Desktop\\\\Evaluation Datasets\\\\Datasets\\\\entity_linking\\\\conll_aida-yago2-dataset\\\\AIDA-YAGO2-dataset.tsv_nif\"\n",
    "\n",
    "nif_data = \"\"\n",
    "\n",
    "with open(nif_data_path, 'r', encoding=\"utf-8\") as f:\n",
    "    nif_data = f.read()\n",
    "\n",
    "parsed_collection = NIFCollection.loads(nif_data, format='turtle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stork H1 results breakdown per sector .  AMSTERDAM 1996-08-28  First 24 weeks 1996  ( millions of guilders unless otherwise stated )  Industrial systems and components  - Turnover 756 vs 829  - Operating profit 46 vs 48  - New orders received 876 vs 933  - Order book ( billions ) 1.07 vs 0.98  Industrial services  - Turnover 657 vs 700  - Operating profit 9 vs 3  - New orders received ( billions ) 1.00 vs 1.09  - Order book ( billions ) 2.37 vs 2.01  NOTE - Order book figures refer to value of orders on books at end of period .  -- Amsterdam newsroom +31 20 504 5000 , Fax +31 20 504 5040 , 0, 595\n",
      "AMSTERDAM, 41, 50, https://aifb.kit.edu/conll/768#offset_41_50, None, http://en.wikipedia.org/wiki/Amsterdam\n",
      "Amsterdam, 538, 547, https://aifb.kit.edu/conll/768#offset_538_547, None, http://en.wikipedia.org/wiki/Amsterdam\n"
     ]
    }
   ],
   "source": [
    "for context in parsed_collection.contexts:\n",
    "    # See what can be called on context\n",
    "    # print(dir(context))\n",
    "\n",
    "    # input sentence (1 document = 1 sentence)\n",
    "    document = context.mention\n",
    "    print(f\"{context.mention}, {context.beginIndex}, {context.endIndex}\")\n",
    "    for phrase in context.phrases:\n",
    "        #print(phrase)\n",
    "        #print(dir(phrase))\n",
    "        print(f\"{phrase.mention}, {phrase.beginIndex}, {phrase.endIndex}, {phrase.generated_uri}, {phrase.taClassRef}, {phrase.taIdentRef}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dbp_json_cands_to_dict(json_documents={}):\n",
    "    candidate_dict = {}\n",
    "    candidate_dict['types'] = []\n",
    "    candidate_dict['label'] = []\n",
    "    candidate_dict['desc'] = []\n",
    "    candidate_dict['uri'] = []\n",
    "    candidate_dict['score'] = []\n",
    "    candidate_dict['refCount'] = []\n",
    "    \n",
    "    for i in range(len(json_documents)):\n",
    "        document = json_documents[i]\n",
    "        try:\n",
    "            # Retrieve information\n",
    "            # Description\n",
    "            small_desc = document.get('comment', \"\")\n",
    "            # Types for this candidate\n",
    "            types = document.get('typeName', [])\n",
    "            if types is None:\n",
    "                #print(f\"No types for: {document.keys()}, {document['label']}\")\n",
    "                types = \"\"\n",
    "                \n",
    "            # The label / name for this candidate\n",
    "            label = document.get('label', [])\n",
    "            \n",
    "            # URI for this candidate\n",
    "            uri = document.get('resource', [])\n",
    "\n",
    "            # Score (Optional)\n",
    "            score = document.get('score', [])\n",
    "\n",
    "            # Reference Count (Optional)\n",
    "            refCount = document.get('refCount', [])\n",
    "\n",
    "            # Populate information\n",
    "            candidate_dict['types'].append(types)\n",
    "            candidate_dict['label'].extend(label)\n",
    "            candidate_dict['desc'].extend(small_desc)\n",
    "            candidate_dict['uri'].extend(uri)\n",
    "            candidate_dict['score'].extend(score)\n",
    "            candidate_dict['refCount'].extend(refCount)\n",
    "\n",
    "            \n",
    "        except:\n",
    "            print(f\"ERROR: {document.keys()}\")\n",
    "            raise\n",
    "    return candidate_dict['label'], candidate_dict['desc'], candidate_dict['types'], candidate_dict['uri'], candidate_dict['score'], candidate_dict['refCount']\n",
    "\n",
    "\n",
    "labels, desc, types, uris, score, refCount = transform_dbp_json_cands_to_dict(json_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "        \n",
    "def load_candidate_results(\n",
    "                          result_directory=\"C:/Users/wf7467/Desktop/GitHub/KIT/agnostic-disambiguation/data/candidates/CoNLL_AIDA-YAGO2-dataset.nif/\"):\n",
    "    all_candidate_results = {}\n",
    "    for path in [result_directory+f for f in listdir(result_directory) if isfile(join(result_directory, f))]:\n",
    "        with open(path, encoding='utf-8') as json_file:\n",
    "            in_json = json.load(json_file)\n",
    "            \n",
    "            all_candidate_results[path] = in_json\n",
    "    return all_candidate_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mention data\n",
    "from pynif import NIFCollection\n",
    "\n",
    "def load_nif_dataset(nif_data_path = \"C:\\\\Users\\\\wf7467\\\\Desktop\\\\Evaluation Datasets\\\\Datasets\\\\entity_linking\\\\conll_aida-yago2-dataset\\\\AIDA-YAGO2-dataset.tsv_nif\"):\n",
    "\n",
    "    nif_data = \"\"\n",
    "\n",
    "    with open(nif_data_path, 'r', encoding=\"utf-8\") as f:\n",
    "        nif_data = f.read()\n",
    "\n",
    "    parsed_collection = NIFCollection.loads(nif_data, format='turtle')\n",
    "\n",
    "parsed_collection = load_nif_dataset(nif_data_path = \"C:\\\\Users\\\\wf7467\\\\Desktop\\\\Evaluation Datasets\\\\Datasets\\\\entity_linking\\\\conll_aida-yago2-dataset\\\\AIDA-YAGO2-dataset.tsv_nif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1393\n"
     ]
    }
   ],
   "source": [
    "all_candidate_results = load_candidate_results(result_directory=\"C:/Users/wf7467/Desktop/GitHub/KIT/agnostic-disambiguation/data/candidates/CoNLL_AIDA-YAGO2-dataset.nif/\")\n",
    "print(f\"Number of entries: {len(all_candidate_results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/wf7467/Desktop/GitHub/KIT/agnostic-disambiguation/data/candidates/CoNLL_AIDA-YAGO2-dataset.nif/1006.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['mentions', 'begin_index', 'end_index', 'labels', 'desc', 'types', 'candidate_uris', 'scores', 'refCount', 'true_uris'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get some random key to get one entry\n",
    "key = (list(all_candidate_results.keys()))[10]\n",
    "#print(all_candidate_results[list(all_candidate_results.keys())[10]])\n",
    "print(key)\n",
    "#key = next(iter(all_candidate_results))\n",
    "candidates_entry = all_candidate_results[key]\n",
    "# Only has one key\n",
    "in_text = next(iter( candidates_entry ))\n",
    "json_candidates = candidates_entry[in_text]\n",
    "json_candidates.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cand_desc_results(\n",
    "                          result_directory=\"C:/Users/wf7467/Desktop/GitHub/KIT/agnostic-disambiguation/data/candidate_descriptions/CoNLL_AIDA-YAGO2-dataset.nif/\"):\n",
    "    '''Taken from query_data.ipynb'''\n",
    "    all_cand_desc_results = {}\n",
    "    for path in [result_directory+f for f in listdir(result_directory) if isfile(join(result_directory, f))]:\n",
    "        with open(path, encoding='utf-8') as json_file:\n",
    "            in_json = json.load(json_file)\n",
    "            \n",
    "            all_cand_desc_results[path] = in_json\n",
    "    return all_cand_desc_results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_dict_candidate_description():\n",
    "    all_cand_desc_results = load_cand_desc_results()\n",
    "    # uris_for_descriptions --> all URIs we want to crawl\n",
    "    # cands_desc\n",
    "\n",
    "    dict_uri_desc = {}\n",
    "    for filename in all_cand_desc_results:\n",
    "        cands_desc = all_cand_desc_results[filename]\n",
    "        #print(list(cands_desc.keys())[0])\n",
    "        for uri in cands_desc:\n",
    "            desc = cands_desc[uri]\n",
    "            dict_uri_desc[uri] = desc\n",
    "    return dict_uri_desc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save it globally to avoid long call chains...\n",
    "dict_uri_description = load_dict_candidate_description()\n",
    "\n",
    "\n",
    "def get_or_default_lst(lst, idx, default):\n",
    "    return lst[idx] if idx < len(lst) else default\n",
    "\n",
    "\n",
    "def generate_prompt_options(json_candidates, i, newline='\\n'):\n",
    "    # i-th mention\n",
    "    # j-th candidate\n",
    "    prompt_options = []\n",
    "    prompt_options_w_desc = []\n",
    "    candidate_uris = []\n",
    "    for j in range(len(json_candidates)):\n",
    "        mention = json_candidates['mentions'][i]\n",
    "        # Types for this one candidate\n",
    "        types_list = get_or_default_lst(json_candidates['types'], i, [])\n",
    "        types_list = get_or_default_lst(types_list, j, [])\n",
    "        types = ', '.join(types_list)\n",
    "        \n",
    "        # this candidate's URI\n",
    "        uri_list = get_or_default_lst(json_candidates['candidate_uris'], i, [])\n",
    "        uri = get_or_default_lst(uri_list, j, \"\")\n",
    "        \n",
    "        # Description for this candidate\n",
    "        desc = dict_uri_description.get(uri, \"\")\n",
    "\n",
    "        #desc_list = get_or_default_lst(json_candidates['desc'], i, [])\n",
    "        #desc = get_or_default_lst(desc_list, j, \"\")\n",
    "        \n",
    "        prompt_choice = f\"{j}. { mention } ({ types }) - { uri }\"\n",
    "        prompt_choice_w_desc = prompt_choice + f\" {newline}{ desc }\"\n",
    "        prompt_options_w_desc.append(prompt_choice_w_desc)\n",
    "        prompt_options.append(prompt_choice)\n",
    "        candidate_uris.append(uri)\n",
    "    \n",
    "    return prompt_options_w_desc, prompt_options, candidate_uris\n",
    "\n",
    "\n",
    "def generate_prompt_from_candidates(json_candidates, input_document):\n",
    "    newline = \"\\n\"\n",
    "    mention_prompts = []\n",
    "    mention_prompt_choices = []\n",
    "    mention_candidate_uris = []\n",
    "    \n",
    "    #input_document, mentions, labels, candidate_uris\n",
    "    for mention_index in range(len(json_candidates['mentions'])):\n",
    "        prompt_options_w_desc, prompt_choices, candidate_uris = generate_prompt_options(json_candidates=json_candidates, i=mention_index)\n",
    "        mention_prompt_choices.append(prompt_choices)\n",
    "        mention_candidate_uris.append(candidate_uris)\n",
    "        prompt_text = f\"\"\"For the input document \\\"{input_document}\\\", which of the following entity candidates - if any - is referred to by the mention \\\"{json_candidates['mentions'][mention_index]}\\\" (at offset {json_candidates['begin_index'][mention_index]})?\n",
    "\n",
    "Descriptions:\n",
    "{(newline+newline).join(prompt_options_w_desc)}\"\"\"\n",
    "        \n",
    "        mention_prompts.append(prompt_text)\n",
    "    return mention_prompts, json_candidates['true_uris'], mention_prompt_choices, mention_candidate_uris\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mention_prompts, true_uris, mention_prompt_choices, mention_candidate_uris = generate_prompt_from_candidates(json_candidates, input_document=in_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuzzy string matching library\n",
    "#!pip install thefuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matching_choice(response: str, choices: list):\n",
    "    # Return best rated index for passed list\n",
    "    max_ratio = 0\n",
    "    max_ratio_idx = 0\n",
    "    response = response.lower()\n",
    "    #print(f\"To match:{response}\")\n",
    "    for choice_idx in range(len(choices)):\n",
    "        choice = choices[choice_idx].lower()\n",
    "        \n",
    "        if len(response) < len(choice):\n",
    "            shorter = response\n",
    "            longer = choice\n",
    "        else:\n",
    "            shorter = choice\n",
    "            longer = response\n",
    "            \n",
    "        new_ratio = fuzz.partial_ratio(shorter, longer)\n",
    "        #print(f\"{choice}: {new_ratio}\")\n",
    "        if new_ratio > max_ratio:\n",
    "            max_ratio = new_ratio\n",
    "            max_ratio_idx = choice_idx\n",
    "        if max_ratio >= 100:\n",
    "            # Quick closure on exact matches...\n",
    "            return max_ratio_idx\n",
    "    return max_ratio_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from huggingface_hub import InferenceClient\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "# Fuzzy matching for LLM responses\n",
    "from thefuzz import fuzz\n",
    "\n",
    "def query_LLM(input_document=\"\", json_candidates={}, endpoint_url=\"http://aifb-websci-gpunode2.aifb.kit.edu:8081\", \\\n",
    "              model_id=\"meta-llama/Meta-Llama-3-8B-Instruct\"):\n",
    "\n",
    "    tokenizer=AutoTokenizer.from_pretrained(model_id)\n",
    "    y_pred_dbp = []\n",
    "    y_true = []\n",
    "\n",
    "    # Generate prompts for what we want\n",
    "    mention_prompts, true_uris, mention_prompt_choices, mention_candidate_uris = generate_prompt_from_candidates(json_candidates, input_document=input_document)\n",
    "\n",
    "    client = InferenceClient(endpoint_url)\n",
    "\n",
    "    # One prompt per mention is executed\n",
    "    for i in tqdm_notebook(range(len(mention_prompts))):\n",
    "        #print(f\"Query Numero #{i}\")\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert assistant disambiguating entities and outputting if any of the passed entities are referenced in a given input text.\"},\n",
    "            #{\"role\": \"user\", \"content\": f\"Please convert this text into triples: 'Green Day is a rock band.'\"},            \n",
    "            #{\"role\": \"assistant\", \"content\": \"Here are the triples corresponding to 'Green Day is a rock band.': (Green Day, has type, rock band)\"},\n",
    "            #{\"role\": \"user\", \"content\": f\"Please convert this text into triples: 'New York is a city in North America.'\"},            \n",
    "            #{\"role\": \"assistant\", \"content\": \"Here are the triples corresponding to 'New York is a city in North America': (New York, has type, city), (New York, located in, North America)\"},\n",
    "            {\"role\": \"user\", \"content\": prompt_text_apple},\n",
    "            {\"role\": \"assistant\", \"content\": \"The correct disambiguated entity is number 2. Apple Inc. (Public company) - http://dbpedia.org/resource/Apple_Inc.\"},\n",
    "            #{\"role\": \"user\", \"content\": prompt_text_steve},\n",
    "            #{\"role\": \"assistant\", \"content\": \"The correct disambiguated entity is number 11. Steve Jobs (animal) - http://dbpedia.org/resource/Steve_Jobs\"},\n",
    "            {\"role\": \"user\", \"content\": mention_prompts[i]},\n",
    "            {\"role\": \"assistant\", \"content\": \"The correct disambiguated entity is number\"},\n",
    "        ]\n",
    "\n",
    "        prompt = tokenizer.apply_chat_template(\n",
    "                messages, \n",
    "                tokenize=False, \n",
    "                add_generation_prompt=True\n",
    "        )\n",
    "\n",
    "\n",
    "        response = client.text_generation(\n",
    "          prompt + f\"The correct disambiguated entity is number\",\n",
    "          max_new_tokens=64,\n",
    "          do_sample=False,\n",
    "          temperature=0.01,\n",
    "                stop_sequences=[\"<|start_header_id|>\", \"<|end_header_id|>\", \"<|eot_id|>\"]\n",
    "        )\n",
    "        #print(prompt + response)\n",
    "        \n",
    "        #print(f\"Wanted entity: {true_uris[i]}\")\n",
    "        #print(f\"RESPONSE is: {response}\")\n",
    "        choice_index = find_matching_choice(response, mention_prompt_choices[i])\n",
    "        #print(f\"Candidate Option #{choice_index}: {mention_prompt_choices[i][choice_index]} was chosen.\")\n",
    "        # See if given answer matches the true label\n",
    "        chosen_candidate = mention_candidate_uris[i][choice_index]\n",
    "        wanted_candidate = true_uris[i]\n",
    "        #print(f\"Chosen[{chosen_candidate}] vs. wanted[{wanted_candidate}]\")\n",
    "        y_true.append(wanted_candidate)\n",
    "        y_pred_dbp.append(chosen_candidate)\n",
    "    \n",
    "    return y_true, y_pred_dbp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_results(y_pred, y_true, average='macro'):\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    #print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    # Calculate precision\n",
    "    precision = precision_score(y_true, y_pred, average=average)\n",
    "    #print(\"Precision:\", precision)\n",
    "\n",
    "    # Calculate recall (sensitivity)\n",
    "    recall = recall_score(y_true, y_pred, average=average)\n",
    "    #print(\"Recall (Sensitivity):\", recall)\n",
    "\n",
    "    # Calculate F1-score\n",
    "    f1 = f1_score(y_true, y_pred, average=average)\n",
    "    #print(\"F1-Score:\", f1)\n",
    "    \n",
    "    return {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import json\n",
    "\n",
    "def persist_prompt_and_results(output_directory, in_filepath, input_document, mention_prompts, y_true, y_pred, mention_prompt_choices, mention_candidate_uris, eval_results):\n",
    "    # Build a great json!\n",
    "    prompt_dict = {}\n",
    "    prompt_dict['cand path'] = in_filepath\n",
    "    prompt_dict['doc'] = input_document\n",
    "    prompt_dict['mention_prompts'] = mention_prompts\n",
    "    prompt_dict['y_true'] = y_true\n",
    "    prompt_dict['y_pred'] = y_pred\n",
    "    prompt_dict['mention_prompt_choices'] = mention_prompt_choices\n",
    "    prompt_dict['mention_candidate_uris'] = mention_candidate_uris\n",
    "    prompt_dict['eval_results'] = eval_results\n",
    "    \n",
    "    \n",
    "    with open(output_directory+str(os.path.basename(in_filepath)), 'w', encoding='utf-8') as f:\n",
    "        json.dump(prompt_dict, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "        \n",
    "def load_prompt_and_results(result_directory):\n",
    "    prompt_dicts = {}\n",
    "    for path in [result_directory+f for f in listdir(result_directory) if isfile(join(result_directory, f))]:\n",
    "        with open(path, encoding='utf-8') as json_file:\n",
    "            prompt_dict = json.load(json_file)\n",
    "            prompt_dicts[path] = prompt_dict\n",
    "    return prompt_dicts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All in one cell\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "def load_dataset_queryLLM_evaluate(nif_data_path = \"C:\\\\Users\\\\wf7467\\\\Desktop\\\\Evaluation Datasets\\\\Datasets\\\\entity_linking\\\\conll_aida-yago2-dataset\\\\AIDA-YAGO2-dataset.tsv_nif\", \\\n",
    "                                   cand_result_directory = \"C:/Users/wf7467/Desktop/GitHub/KIT/agnostic-disambiguation/data/candidates/CoNLL_AIDA-YAGO2-dataset.nif/\",\n",
    "                                  output_directory=\"C:/Users/wf7467/Desktop/GitHub/KIT/agnostic-disambiguation/data/disambiguation/\"):\n",
    "    \n",
    "    #print(\"[Loading NIF dataset] Started.\")\n",
    "    #dataset = load_nif_dataset(nif_data_path= nif_data_path)\n",
    "    #print(\"[Loading NIF dataset] Completed.\")\n",
    "    print(\"[Loading candidate results] Started.\")\n",
    "    all_candidate_results = load_candidate_results(result_directory= cand_result_directory)\n",
    "    print(\"[Loading candidate results] Completed.\")\n",
    "    print(f\"Number of entries: {len(all_candidate_results)}\")\n",
    "\n",
    "\n",
    "    # Iterate through all entries\n",
    "    for key in tqdm_notebook(all_candidate_results, position=0):\n",
    "        #get some random key to get one entry\n",
    "        #key = (list(all_candidate_results.keys()))[10]\n",
    "        #print(all_candidate_results[list(all_candidate_results.keys())[10]])\n",
    "        \n",
    "        #print(key)#file name of which candidates were loaded from\n",
    "        #key = next(iter(all_candidate_results))\n",
    "        candidates_entry = all_candidate_results[key]\n",
    "        # Only has one key\n",
    "        input_document = next(iter( candidates_entry ))\n",
    "\n",
    "        json_candidates = candidates_entry[input_document]\n",
    "\n",
    "        # Generate prompts and get the possible choices, candidates etc. for choice matching and evaluation\n",
    "        mention_prompts, true_uris, mention_prompt_choices, mention_candidate_uris = generate_prompt_from_candidates(json_candidates, input_document=input_document)\n",
    "\n",
    "        #query_LLM\n",
    "        #print(input_document)\n",
    "        y_true, y_pred = query_LLM(input_document, json_candidates, endpoint_url = \"http://aifb-websci-gpunode2.aifb.kit.edu:8081\", model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\")\n",
    "\n",
    "        # Evaluate this document\n",
    "        y_pred_wiki = [y.replace('http://dbpedia.org/resource/', 'http://en.wikipedia.org/wiki/') for y in y_pred]\n",
    "\n",
    "        eval_results = evaluate_results(y_pred_wiki, y_true)\n",
    "        \n",
    "        # Save all results to files\n",
    "        persist_prompt_and_results(output_directory, key, input_document, mention_prompts, y_true, y_pred, mention_prompt_choices, mention_candidate_uris, eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "load_dataset_queryLLM_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_result_dicts = load_prompt_and_results(result_directory=\"C:/Users/wf7467/Desktop/GitHub/KIT/agnostic-disambiguation/data/disambiguation/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_true = []\n",
    "all_pred = []\n",
    "scored_results = []\n",
    "\n",
    "for key in prompt_result_dicts.keys():\n",
    "    y_true = prompt_result_dicts[key]['y_true']\n",
    "    y_pred = prompt_result_dicts[key]['y_pred']\n",
    "    y_pred_wiki = [y.replace('http://dbpedia.org/resource/', 'http://en.wikipedia.org/wiki/') for y in y_pred]\n",
    "    if len(y_true) != len(y_pred):\n",
    "        print(f\"Error with lengths... {key}\")\n",
    "        print(prompt_result_dicts[key])\n",
    "        raise ValueError(f\"True:{ y_true } vs. Pred:{ y_pred }\")\n",
    "    all_true.extend(y_true)\n",
    "    all_pred.extend(y_pred_wiki)\n",
    "    eval_results = evaluate_results(y_pred_wiki, y_true, 'macro')\n",
    "    scored_results.append((eval_results['f1'], key))\n",
    "\n",
    "\n",
    "print(evaluate_results(all_pred, all_true, 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_results.sort(key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_results[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test some baselines\n",
    "test_question = \"What Wikipedia entity does the first occurrence of Ethiopia refer to in the following text?\\n\"\n",
    "test_in_text = \"SOCCER - AFRICAN NATIONS CUP COLLATED RESULTS .  JOHANNESBURG 1996-08-26  Collated results of African Nations Cup preliminary round , second leg matches played at the weekend :  Ethiopia 1 Uganda 1  2-2 on aggregate .  Ethiopia win 4-2 on penalties  Mauritania v Benin postponed to Friday  Benin lead 4-1 from the first leg  Namibia 6 Botswana 0  Namibia win 6-0 on aggregate  Seychelles 1 Mauritius 1  Mauritius win 2-1 on aggregate  Togo 1 Congo 0  Togo win 1-0 on aggregaete  Central African Republic walkover v Burundi  Winners progress to qualifying groups to start in October .\"\n",
    "test_prompt = test_question + \"\\n\" + test_in_text\n",
    "\n",
    "test_question_which = \"Which of the following candidates fits the description of \"\n",
    "test_candidates = \"\\n0. Ethiopia (Place, Country, PopulatedPlace, Location) - http://dbpedia.org/resource/Ethiopia \\n<B>Ethiopia</B> (; Amharic: áŠ¢á‰µá‹®áŒµá‹«, Ê¾ÄªtyÅ�á¹—á¹—yÄ�, , Tigrinya: áŠ¢á‰µá‹®áŒµá‹«, Oromo: Itoophiyaa, Somali: Itoobiya, Afar\\n\\n1. Ethiopia () - http://dbpedia.org/resource/Districts_of_Ethiopia \\n divisions of <B>Ethiopia</B>. They are further subdivided into a number of wards (kebele) or neighbourhood\\n\\n2. Ethiopia (Place, Country, PopulatedPlace, Location) - http://dbpedia.org/resource/Ethiopian_Empire \\n <B>Ethiopia</B> (; Ge'ez: áŠ¢á‰µá‹®áŒµá‹«, Amharic: áŠ¢á‰µá‹®áŒµá‹«, Ê¾ÄªtyÅ�á¹—á¹—yÄ�, , Tigrinya: áŠ¢á‰µá‹®áŒµá‹«, Oromo: Itoophiyaa, Somali\\n\\n3. Ethiopia (AdministrativeRegion, Place, PopulatedPlace, Location, Region) - http://dbpedia.org/resource/Amhara_Region \\n of <B>Ethiopia</B>, containing the homeland of the Amhara people. Previously known as \\\"Region 3\\\", its capital\\n\\n4. Ethiopia () - http://dbpedia.org/resource/Ethiopia–United_States_relations \\n<B>Ethiopia</B>–United States relations are bilateral relations between <B>Ethiopia</B> and the United States\\n\\n5. Ethiopia (Organisation, SoccerClub, Agent, SportsClub) - http://dbpedia.org/resource/Ethiopia_national_football_team \\nThe <B>Ethiopia</B> national football team, nicknamed Walias, after the Walia ibex, represents <B>Ethiopia</B>\\n\\n6. Ethiopia (Settlement, City, Place, PopulatedPlace, Location) - http://dbpedia.org/resource/Addis_Ababa \\n of <B>Ethiopia</B>. According to the 2007 census, the city has a population of 2,739,551 inhabitants. The city\\n\\n7. Ethiopia () - http://dbpedia.org/resource/Regions_of_Ethiopia \\n<B>Ethiopia</B> is a federation subdivided into ethno-linguistically based Regional States (plural\\n\\n8. Ethiopia () - http://dbpedia.org/resource/Emperor_of_Ethiopia \\nThe Emperor of <B>Ethiopia</B> (Ge'ez: áŠ•áŒ‰áˆ  áŠ�áŒˆáˆ¥á‰µ, nÉ™gusÃ¤ nÃ¤gÃ¤st, \\\"King of Kings\\\") was the hereditary ruler\\n\\n9. Ethiopia () - http://dbpedia.org/resource/Demographics_of_Ethiopia \\nThe demographics of <B>Ethiopia</B> encompass the demographic features of <B>Ethiopia's</B> inhabitants\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "def prompt_LLM(messages = []):\n",
    "\n",
    "    endpoint_url = \"http://aifb-websci-gpunode2.aifb.kit.edu:8081\"\n",
    "    model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "    client = InferenceClient(endpoint_url)\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "            messages, \n",
    "            tokenize=False, \n",
    "            add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "\n",
    "    response = client.text_generation(\n",
    "      prompt,# + f\"The correct disambiguated entity is number\",\n",
    "      max_new_tokens=64,\n",
    "      do_sample=False,\n",
    "      temperature=0.01,\n",
    "            stop_sequences=[\"<|start_header_id|>\", \"<|end_header_id|>\", \"<|eot_id|>\"]\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "first_round_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a very well paid expert assistant disambiguating Wikipedia entities from texts.\"},\n",
    "    #{\"role\": \"user\", \"content\": f\"Please convert this text into triples: 'Green Day is a rock band.'\"},            \n",
    "    #{\"role\": \"assistant\", \"content\": \"Here are the triples corresponding to 'Green Day is a rock band.': (Green Day, has type, rock band)\"},\n",
    "    #{\"role\": \"user\", \"content\": f\"Please convert this text into triples: 'New York is a city in North America.'\"},            \n",
    "    #{\"role\": \"assistant\", \"content\": \"Here are the triples corresponding to 'New York is a city in North America': (New York, has type, city), (New York, located in, North America)\"},\n",
    "    #{\"role\": \"user\", \"content\": f\"Please convert this text into triples: 'Kris is a researcher'\"},\n",
    "    #\n",
    "    #{\"role\": \"user\", \"content\": prompt_text_apple},\n",
    "    #{\"role\": \"assistant\", \"content\": \"The correct disambiguated entity is number 2. Apple Inc. (Public company) - http://dbpedia.org/resource/Apple_Inc.\"},\n",
    "    #{\"role\": \"user\", \"content\": prompt_text_steve},\n",
    "    #{\"role\": \"assistant\", \"content\": \"The correct disambiguated entity Steve Jobs - http://wikipedia.org/page/Steve_Jobs\"},\n",
    "    {\"role\": \"user\", \"content\": test_prompt},\n",
    "    {\"role\": \"assistant\", \"content\": \"The first occurrence of \\\"Ethiopia\\\" in the text refers to the\"},\n",
    "    \n",
    "]\n",
    "\n",
    "second_round_messages = first_round_messages[0:-2]\n",
    "second_round_messages.extend([{\"role\": \"user\", \"content\": test_prompt_which}, ])\n",
    "\n",
    "\n",
    "entity_desc = prompt_LLM(first_round_messages)\n",
    "\n",
    "test_prompt_which = test_question_which + entity_desc + \"\\n\" + test_candidates\n",
    "\n",
    "print(response)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt_LLM([{\"role\": \"user\", \"content\": \"\"\"Given the sentence \\\"Steve eats an apple,\\\" select the appropriate Wikipedia entity for the term \\\"apple\\\" from the following options:\n",
    "\n",
    "1. Apple Inc. - A multinational technology company that designs, manufactures, and sells consumer electronics, software, and online services. Known for products like the iPhone, iPad, and MacBook.\n",
    "\n",
    "2. Apple (Name) - A given name or surname. Sometimes used as a personal name.\n",
    "\n",
    "3. Apple (Fruit) - The edible fruit produced by an apple tree (Malus domestica). Commonly eaten raw or used in cooking and baking.\n",
    "\n",
    "4. Apple (Symbolism) - A symbol used in various cultural, religious, and artistic contexts. Often represents knowledge, immortality, temptation, or sin.\"\"\"}]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODOs for evaluation:</br>\n",
    "* sameAs links</br>\n",
    "* is dbo:wikiPageRedirects of</br>\n",
    "        * Example: http://en.wikipedia.org/wiki/People's_Republic_of_China vs. http://dbpedia.org/resource/China</br>\n",
    "        * Relevant file: C:/Users/wf7467/Desktop/GitHub/KIT/agnostic-disambiguation/data/candidates/CoNLL_AIDA-YAGO2-dataset.nif/1.json</br>\n",
    "    * dbr:People's_Republic_Of_China</br>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
